{"version":3,"sources":["../src/max-ten.js"],"names":["defaultOptions","max","strict","isSandwichedMeishi","before","token","after","undefined","pos","addPositions","base","relative","line","column","module","exports","context","options","maxLen","isStrict","helper","Syntax","RuleError","report","getSource","Paragraph","node","isChildNode","BlockQuote","sentences","charRegExp","newLineCharacters","then","forEach","text","sentence","value","source","currentTenCount","tokens","tokenizer","tokenizeForSentence","lastToken","index","surface","surface_form","isSandwiched","positionInSentence","indexToPosition","word_position","positionInNode","loc","start","ruleError"],"mappings":"AAAA;AACA;;AACA;;AACA;;AACA;;AACA;;;;;;;;AACA,IAAMA,iBAAiB;AACnBC,SAAK,CADc,EACX;AACRC,YAAQ,KAFW,CAEL;AAFK,CAAvB;;AAKA,SAASC,kBAAT,OAIG;AAAA,QAHCC,MAGD,QAHCA,MAGD;AAAA,QAFCC,KAED,QAFCA,KAED;AAAA,QADCC,KACD,QADCA,KACD;;AACC,QAAIF,WAAWG,SAAX,IAAwBD,UAAUC,SAAlC,IAA+CF,UAAUE,SAA7D,EAAwE;AACpE,eAAO,KAAP;AACH;AACD,WAAOH,OAAOI,GAAP,KAAe,IAAf,IAAuBF,MAAME,GAAN,KAAc,IAA5C;AACH;AACD;;;;;;;AAOA,SAASC,YAAT,CAAsBC,IAAtB,EAA4BC,QAA5B,EAAsC;AAClC,WAAO;AACHC,cAAMF,KAAKE,IAAL,GAAYD,SAASC,IAArB,GAA4B,CAD/B,EACkC;AACrCC,gBAAQF,SAASC,IAAT,IAAiB,CAAjB,GAAqBF,KAAKG,MAAL,GAAcF,SAASE,MAA5C,CAAmD;AAAnD,UACFF,SAASE,MAHZ,CAGiC;AAHjC,KAAP;AAKH;AACD;;;;AAIAC,OAAOC,OAAP,GAAiB,UAASC,OAAT,EAAgC;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAC7C,QAAMC,SAASD,QAAQhB,GAAR,IAAeD,eAAeC,GAA7C;AACA,QAAMkB,WAAWF,QAAQf,MAAR,IAAkBF,eAAeE,MAAlD;AACA,QAAIkB,SAAS,mCAAeJ,OAAf,CAAb;AAH6C,QAIxCK,MAJwC,GAIAL,OAJA,CAIxCK,MAJwC;AAAA,QAIhCC,SAJgC,GAIAN,OAJA,CAIhCM,SAJgC;AAAA,QAIrBC,MAJqB,GAIAP,OAJA,CAIrBO,MAJqB;AAAA,QAIbC,SAJa,GAIAR,OAJA,CAIbQ,SAJa;;AAK7C,+BACKH,OAAOI,SADZ,YACuBC,IADvB,EAC4B;AACpB,YAAIN,OAAOO,WAAP,CAAmBD,IAAnB,EAAyB,CAACL,OAAOO,UAAR,CAAzB,CAAJ,EAAmD;AAC/C;AACH;AACD,YAAIC,YAAY,6BAAeL,UAAUE,IAAV,CAAf,EAAgC;AAC5CI,wBAAY,WADgC;AAE5CC,+BAAmB;AAFyB,SAAhC,CAAhB;AAIA;;;;;;AAMA;;;;;;AAMA,eAAO,+BAAeC,IAAf,CAAoB,qBAAa;AACpCH,sBAAUI,OAAV,CAAkB,oBAAY;AAC1B,oBAAIC,OAAOC,SAASC,KAApB;AACA,oBAAIC,SAAS,+BAAWH,IAAX,CAAb;AACA,oBAAII,kBAAkB,CAAtB;AACA,oBAAIC,SAASC,UAAUC,mBAAV,CAA8BP,IAA9B,CAAb;AACA,oBAAIQ,YAAY,IAAhB;AACAH,uBAAON,OAAP,CAAe,UAAC5B,KAAD,EAAQsC,KAAR,EAAkB;AAC7B,wBAAIC,UAAUvC,MAAMwC,YAApB;AACA,wBAAID,YAAY,GAAhB,EAAqB;AACjB;AACA,4BAAIE,eAAe3C,mBAAmB;AAClCC,oCAAQmC,OAAOI,QAAQ,CAAf,CAD0B;AAElCtC,mCAAOA,KAF2B;AAGlCC,mCAAOiC,OAAOI,QAAQ,CAAf;AAH2B,yBAAnB,CAAnB;AAKA;AACA,4BAAI,CAACxB,QAAD,IAAa2B,YAAjB,EAA+B;AAC3B;AACH;AACDR;AACAI,oCAAYrC,KAAZ;AACH;AACD,wBAAIuC,YAAY,GAAhB,EAAqB;AACjB;AACAN,0CAAkB,CAAlB;AACH;AACD;AACA,wBAAIA,mBAAmBpB,MAAvB,EAA+B;AAC3B,4BAAI6B,qBAAqBV,OAAOW,eAAP,CAAuBN,UAAUO,aAAV,GAA0B,CAAjD,CAAzB;AACA,4BAAIC,iBAAiBzC,aAAa0B,SAASgB,GAAT,CAAaC,KAA1B,EAAiCL,kBAAjC,CAArB;AACA,4BAAIM,YAAY,IAAIrC,QAAQM,SAAZ,oDAAkCJ,MAAlC,mEAAsD;AAClEN,kCAAMsC,eAAetC,IAAf,GAAsB,CADsC;AAElEC,oCAAQqC,eAAerC;AAF2C,yBAAtD,CAAhB;AAIAU,+BAAOG,IAAP,EAAa2B,SAAb;AACAf,0CAAkB,CAAlB;AACH;AACJ,iBA/BD;AAgCH,aAtCD;AAuCH,SAxCM,CAAP;AAyCH,KA9DL;AAgEH,CArED","file":"max-ten.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport {RuleHelper} from \"textlint-rule-helper\"\nimport {getTokenizer} from \"kuromojin\";\nimport {split as splitSentences} from \"sentence-splitter\";\nimport Source from \"structured-source\";\nconst defaultOptions = {\n    max: 3, // 1文に利用できる最大の、の数\n    strict: false // 例外ルールを適応するかどうか\n};\n\nfunction isSandwichedMeishi({\n    before,\n    token,\n    after\n}) {\n    if (before === undefined || after === undefined || token === undefined) {\n        return false;\n    }\n    return before.pos === \"名詞\" && after.pos === \"名詞\";\n}\n/**\n * add two positions.\n * note: line starts with 1, column starts with 0.\n * @param {Position} base\n * @param {Position} relative\n * @return {Position}\n */\nfunction addPositions(base, relative) {\n    return {\n        line: base.line + relative.line - 1, // line 1 + line 1 should be line 1\n        column: relative.line == 1 ? base.column + relative.column // when the same line\n            : relative.column               // when another line\n    };\n}\n/**\n * @param {RuleContext} context\n * @param {object} [options]\n */\nmodule.exports = function(context, options = {}) {\n    const maxLen = options.max || defaultOptions.max;\n    const isStrict = options.strict || defaultOptions.strict;\n    let helper = new RuleHelper(context);\n    let {Syntax, RuleError, report, getSource} = context;\n    return {\n        [Syntax.Paragraph](node){\n            if (helper.isChildNode(node, [Syntax.BlockQuote])) {\n                return;\n            }\n            let sentences = splitSentences(getSource(node), {\n                charRegExp: /[。\\?\\!？！]/,\n                newLineCharacters: \"\\n\\n\"\n            });\n            /*\n             <p>\n             <str><code><img><str>\n             <str>\n             </p>\n             */\n            /*\n             # workflow\n             1. split text to sentences\n             2. sentence to tokens\n             3. check tokens\n             */\n            return getTokenizer().then(tokenizer => {\n                sentences.forEach(sentence => {\n                    let text = sentence.value;\n                    let source = new Source(text);\n                    let currentTenCount = 0;\n                    let tokens = tokenizer.tokenizeForSentence(text);\n                    let lastToken = null;\n                    tokens.forEach((token, index) => {\n                        let surface = token.surface_form;\n                        if (surface === \"、\") {\n                            // 名詞に過去まわれている場合は例外とする\n                            let isSandwiched = isSandwichedMeishi({\n                                before: tokens[index - 1],\n                                token: token,\n                                after: tokens[index + 1]\n                            });\n                            // strictなら例外を例外としない\n                            if (!isStrict && isSandwiched) {\n                                return;\n                            }\n                            currentTenCount++;\n                            lastToken = token;\n                        }\n                        if (surface === \"。\") {\n                            // reset\n                            currentTenCount = 0;\n                        }\n                        // report\n                        if (currentTenCount >= maxLen) {\n                            let positionInSentence = source.indexToPosition(lastToken.word_position - 1);\n                            let positionInNode = addPositions(sentence.loc.start, positionInSentence);\n                            let ruleError = new context.RuleError(`一つの文で\"、\"を${maxLen}つ以上使用しています`, {\n                                line: positionInNode.line - 1,\n                                column: positionInNode.column\n                            });\n                            report(node, ruleError);\n                            currentTenCount = 0;\n                        }\n                    });\n                });\n            });\n        }\n    }\n}"]}