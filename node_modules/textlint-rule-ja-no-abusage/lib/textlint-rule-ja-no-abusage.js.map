{"version":3,"sources":["../src/textlint-rule-ja-no-abusage.js"],"names":[],"mappings":";AACA;;;;AACA,IAAM,WAAW,QAAQ,WAAR,EAAqB,QAAtC;AACA,IAAM,KAAK,QAAQ,IAAR,CAAX;AACA,IAAM,OAAO,QAAQ,MAAR,CAAb;AACA,IAAM,MAAM,QAAQ,mBAAR,CAAZ;AACA,IAAM,iBAAiB,QAAQ,cAAR,CAAvB;AACA,IAAM,qBAAqB,QAAQ,gBAAR,CAA3B;AACA,IAAM,WAAW,SAAX,QAAW,CAAC,OAAD,EAAa;AAAA,QACnB,MADmB,GAC4B,OAD5B,CACnB,MADmB;AAAA,QACX,SADW,GAC4B,OAD5B,CACX,SADW;AAAA,QACA,MADA,GAC4B,OAD5B,CACA,MADA;AAAA,QACQ,KADR,GAC4B,OAD5B,CACQ,KADR;AAAA,QACe,SADf,GAC4B,OAD5B,CACe,SADf;;AAE1B,QAAM,cAAc,eAAe,GAAf,CAAmB,gBAAQ;AAC3C,eAAO;AACH,qBAAS,mBAAmB,KAAK,QAAL,CAAnB,CADN;AAEH,qBAAS,KAAK,SAAL,CAFN;AAGH,sBAAU,KAAK,UAAL;AAHP,SAAP;AAKH,KANmB,CAApB;AAOA,QAAM,YAAY,IAAI,MAAtB;AACA,QAAM,SAAS,UAAU,OAAV,EAAmB;AAC9B,sBAAc,CACV,GAAG,YAAH,CAAgB,KAAK,IAAL,CAAU,SAAV,EAAqB,IAArB,EAA2B,MAA3B,EAAmC,SAAnC,CAAhB,CADU;AADgB,KAAnB,CAAf;AAKA,+BACK,OAAO,GADZ,YACiB,IADjB,EACsB;AACd,YAAM,OAAO,UAAU,IAAV,CAAb;AACA,eAAO,OAAO,GAAd,EAAmB,IAAnB;AACA,eAAO,SAAS,IAAT,EAAe,IAAf,CAAoB,yBAAiB;AACxC,0BAAc,OAAd,CAAsB,iBAAS;AAC3B,4BAAY,OAAZ,CAAoB,gBAAkC;AAAA,wBAAhC,OAAgC,QAAhC,OAAgC;AAAA,wBAAvB,OAAuB,QAAvB,OAAuB;AAAA,wBAAd,QAAc,QAAd,QAAc;;AAAA,mCAC1B,QAAQ,KAAR,CAD0B;;AAAA,wBAC3C,KAD2C,YAC3C,KAD2C;AAAA,wBACpC,MADoC,YACpC,MADoC;;AAElD,wBAAI,CAAC,KAAL,EAAY;AACR;AACH;AACD,wBAAM,aAAa,OAAO,CAAP,CAAnB;AACA,wBAAM,QAAQ,KAAK,GAAL,CAAS,WAAW,aAAX,GAA2B,CAApC,EAAuC,CAAvC,CAAd;AACA,wBAAI,QAAJ,EAAc;AACV,+BAAO,IAAP,EAAa,IAAI,SAAJ,CAAc,OAAd,EAAuB;AAChC,mCAAO,KADyB;AAEhC,iCAAK,MAAM,gBAAN,CAAuB,CAAC,KAAD,EAAQ,QAAQ,SAAS,MAAzB,CAAvB,EAAyD,QAAzD;AAF2B,yBAAvB,CAAb;AAIH,qBALD,MAKO;AACH,+BAAO,IAAP,EAAa,IAAI,SAAJ,CAAc,OAAd,EAAuB;AAChC,mCAAO;AADyB,yBAAvB,CAAb;AAGH;AACJ,iBAjBD;AAkBH,aAnBD;AAoBH,SArBM,CAAP;AAsBH,KA1BL;AA4BH,CA3CD;AA4CA,OAAO,OAAP,GAAiB;AACb,YAAQ,QADK;AAEb,WAAO;AAFM,CAAjB","file":"textlint-rule-ja-no-abusage.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nconst tokenize = require(\"kuromojin\").tokenize;\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst prh = require(\"textlint-rule-prh\");\nconst dictionaryList = require(\"./dictionary\");\nconst createTokenMatcher = require(\"morpheme-match\");\nconst reporter = (context) => {\n    const {Syntax, RuleError, report, fixer, getSource} = context;\n    const matcherList = dictionaryList.map(dict => {\n        return {\n            matcher: createTokenMatcher(dict[\"tokens\"]),\n            message: dict[\"message\"],\n            expected: dict[\"expected\"]\n        };\n    });\n    const prhLinter = prh.linter;\n    const prhStr = prhLinter(context, {\n        ruleContents: [\n            fs.readFileSync(path.join(__dirname, \"..\", \"dict\", \"prh.yml\"))\n        ]\n    });\n    return {\n        [Syntax.Str](node){\n            const text = getSource(node);\n            prhStr[Syntax.Str](node);\n            return tokenize(text).then(currentTokens => {\n                currentTokens.forEach(token => {\n                    matcherList.forEach(({matcher, message, expected}) => {\n                        const {match, tokens} = matcher(token);\n                        if (!match) {\n                            return;\n                        }\n                        const firstToken = tokens[0];\n                        const index = Math.max(firstToken.word_position - 1, 0);\n                        if (expected) {\n                            report(node, new RuleError(message, {\n                                index: index,\n                                fix: fixer.replaceTextRange([index, index + expected.length], expected)\n                            }));\n                        } else {\n                            report(node, new RuleError(message, {\n                                index: index\n                            }));\n                        }\n                    });\n                });\n            });\n        }\n    }\n};\nmodule.exports = {\n    linter: reporter,\n    fixer: reporter\n};"]}