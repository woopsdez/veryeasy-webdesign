{"version":3,"sources":["../src/analyze.js"],"names":[],"mappings":";AACA;;;;;QAwCgB,U,GAAA,U;QAOA,O,GAAA,O;QAqFA,O,GAAA,O;QA4CA,e,GAAA,e;QASA,Y,GAAA,Y;AAxLhB,IAAM,eAAe,QAAQ,eAAR,CAArB;AACA,IAAM,OAAO,QAAQ,YAAR,CAAb;AACA,IAAM,eAAe,QAAQ,WAAR,EAAqB,YAA1C;;;;;;;;;;;;;AAaA,IAAM,kBAAkB,EAAxB;;;;;AAKA,IAAM,iBAAiB;;;AAGnB,uBAAmB;AAHA,CAAvB;;;;;;;AAWO,IAAM,wBAAQ;AACjB,UAAM,OADW;AAEjB,WAAO;AAFU,CAAd;;;;;AAQA,SAAS,UAAT,CAAoB,YAApB,EAAkC;AACrC,WAAO,aAAa,IAAb,KAAsB,MAAM,IAAnC;AACH;;;;;AAKM,SAAS,OAAT,CAAiB,YAAjB,EAA+B;AAClC,WAAO,aAAa,IAAb,KAAsB,MAAM,KAAnC;AACH;;;;;;;;;AASD,IAAM,cAAc,SAAd,WAAc,CAAC,WAAD,EAAc,SAAd,EAA4B;AAC5C,QAAM,oBAAoB,sBAAsB,WAAtB,EAAmC,SAAnC,CAA1B;AACA,QAAI,sBAAsB,SAA1B,EAAqC;AACjC,eAAO,IAAP;AACH;AACD,QAAM,2BAA2B,kBAAkB,YAAnD;AACA,QAAI,YAAY,IAAZ,CAAiB,wBAAjB,CAAJ,EAAgD;AAC5C,eAAO,IAAP;AACH;AACJ,CATD;;;;;;;AAgBA,IAAM,wBAAwB,SAAxB,qBAAwB,CAAC,WAAD,EAAc,SAAd,EAA4B;AACtD,QAAM,cAAc,KAApB;AACA,QAAM,kBAAkB,IAAxB;AACA,QAAM,qBAAqB,UAAU,OAAV,CAAkB,WAAlB,CAA3B;;AAEA,QAAM,aAAa,UAAU,KAAV,CAAgB,qBAAqB,CAArC,CAAnB;AACA,WAAO,KAAK,UAAL,EAAiB,iBAAS;;AAE7B,YAAI,YAAY,IAAZ,CAAiB,MAAM,cAAN,CAAjB,CAAJ,EAA6C;AACzC,mBAAO,IAAP;AACH;;AAED,YAAI,gBAAgB,IAAhB,CAAqB,MAAM,iBAAN,CAArB,CAAJ,EAAoD;AAChD,mBAAO,IAAP;AACH;;AAED,YAAI,MAAM,KAAN,MAAiB,IAArB,EAA2B;AACvB,mBAAO,IAAP;AACH;AACD,eAAO,KAAP;AACH,KAdM,CAAP;AAeH,CArBD;;;;;;AA2BA,IAAM,sBAAsB,SAAtB,mBAAsB,SAAU;;;;;AAKlC,WAAO,SAAS,wBAAT,CAAkC,KAAlC,EAAyC;AAC5C,YAAM,qBAAqB,OAAO,OAAP,CAAe,KAAf,CAA3B;AACA,YAAM,oBAAoB,sBAAsB,KAAtB,EAA6B,MAA7B,CAA1B;;AAEA,YAAM,iBAAiB,oBAAoB,OAAO,OAAP,CAAe,iBAAf,CAApB,GAAwD,OAAO,MAAtF;AACA,YAAM,cAAc,OAAO,KAAP,CAAa,kBAAb,EAAiC,iBAAiB,CAAlD,CAApB;AACA,YAAM,QAAQ,YAAY,GAAZ,CAAgB;AAAA,mBAAS,MAAM,cAAN,CAAT;AAAA,SAAhB,EAAgD,IAAhD,CAAqD,EAArD,CAAd;AACA,eAAO;AACH,kBAAM,MAAM,iBAAN,CADH;AAEH,mBAAO,KAFJ;AAGH,qBAAS,MAAM,cAAN,CAHN;;AAKH,mBAAO,MAAM,eAAN,IAAyB,CAL7B;;;;AASH,mBAAO,aAAa,EAAb,EAAiB,KAAjB;AATJ,SAAP;AAWH,KAlBD;AAmBH,CAxBD;;;;;;;AA+BO,SAAS,OAAT,CAAiB,IAAjB,EAAiD;AAAA,QAA1B,OAA0B,yDAAhB,cAAgB;;AACpD,QAAM,oBAAoB,QAAQ,iBAAR,KAA8B,SAA9B,GACpB,QAAQ,iBADY,GAEpB,eAAe,iBAFrB;AAGA,WAAO,eAAe,IAAf,CAAoB,qBAAa;AACpC,YAAM,SAAS,gBAAgB,IAAhB,IAAwB,gBAAgB,IAAhB,CAAxB,GAAgD,UAAU,mBAAV,CAA8B,IAA9B,CAA/D;AACA,wBAAgB,IAAhB,IAAwB,MAAxB;AACA,YAAM,eAAe,OAAO,MAAP,CAAc,UAAC,KAAD,EAAQ,KAAR,EAAkB;AACjD,gBAAM,YAAY,OAAO,QAAQ,CAAf,CAAlB;;AAEA,gBAAM,iBAAiB,MAAM,iBAAN,CAAvB;AACA,gBAAI,mBAAmB,MAAM,KAA7B,EAAoC;;AAEhC,oBAAI,MAAM,KAAN,MAAiB,KAAjB,IAA0B,MAAM,iBAAN,MAA6B,KAA3D,EAAkE;AAC9D,wBAAI,aAAa,UAAU,iBAAV,MAAiC,SAAlD,EAA6D;;AAEzD,4BAAI,iBAAJ,EAAuB;AACnB,mCAAO,YAAY,KAAZ,EAAmB,MAAnB,CAAP;AACH,yBAFD,MAEO;AACH,mCAAO,IAAP;AACH;AACJ;AACJ;AACJ,aAZD,MAYO,IAAI,mBAAmB,MAAM,IAA7B,EAAmC;;AAEtC,oBAAI,MAAM,iBAAN,MAA6B,KAAjC,EAAwC;;AAEpC,wBAAI,iBAAJ,EAAuB;AACnB,+BAAO,YAAY,KAAZ,EAAmB,MAAnB,CAAP;AACH,qBAFD,MAEO;AACH,+BAAO,IAAP;AACH;AACJ;AACJ;AACJ,SA3BoB,CAArB;AA4BA,eAAO,aAAa,GAAb,CAAiB,oBAAoB,MAApB,CAAjB,CAAP;AACH,KAhCM,CAAP;AAiCH;;;;;;;AAOM,SAAS,eAAT,CAAyB,IAAzB,EAAyD;AAAA,QAA1B,OAA0B,yDAAhB,cAAgB;;AAC5D,WAAO,QAAQ,IAAR,EAAc,OAAd,EAAuB,IAAvB,CAA4B;AAAA,eAAW,QAAQ,MAAR,CAAe,UAAf,CAAX;AAAA,KAA5B,CAAP;AACH;;;;;;;AAOM,SAAS,YAAT,CAAsB,IAAtB,EAAsD;AAAA,QAA1B,OAA0B,yDAAhB,cAAgB;;AACzD,WAAO,QAAQ,IAAR,EAAc,OAAd,EAAuB,IAAvB,CAA4B;AAAA,eAAW,QAAQ,MAAR,CAAe,OAAf,CAAX;AAAA,KAA5B,CAAP;AACH","file":"analyze.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nconst ObjectAssign = require(\"object.assign\");\nconst find = require('array-find');\nconst getTokenizer = require(\"kuromojin\").getTokenizer;\n/**\n * token object\n * @typedef {{word_id: number, word_type: string, word_position: number, surface_form: string, pos: string, pos_detail_1: string, pos_detail_2: string, pos_detail_3: string, conjugated_type: string, conjugated_form: string, basic_form: string, reading: string, pronunciation: string}} AnalyzedToken\n * @see https://github.com/takuyaa/kuromoji.js#api\n */\n\n/**\n * Analyzed result Object\n * @typedef {{type:string, value:string, surface: string, token:AnalyzedToken, index: number}} AnalyzedResultObject\n */\n\n// Cache tokens\nconst _tokensCacheMap = {};\n/**\n * デフォルトのオプション値\n * @type {{ignoreConjunction: boolean}}\n */\nconst defaultOptions = {\n    // 接続的な \"である\" を無視する\n    // e.g.) 今日はいい天気であるが明日はどうなるかは分からない。\n    ignoreConjunction: false\n};\n/**\n * Type enum\n * @type {{desu: string, dearu: string}}\n * @example\n *  analyze(text).filter(results => results.type === Types.desu);\n */\nexport const Types = {\n    desu: \"特殊・デス\",\n    dearu: \"特殊・ダ\"\n};\n/**\n * @param {AnalyzedResultObject} resultObject\n * @returns {boolean}\n */\nexport function isDesumasu(resultObject) {\n    return resultObject.type === Types.desu;\n}\n/**\n * @param {AnalyzedResultObject} resultObject\n * @returns {boolean}\n */\nexport function isDearu(resultObject) {\n    return resultObject.type === Types.dearu;\n}\n\n/**\n * tokenが文末のtokenなのかどうか\n * 文末とは\"。\"やこれ以上後ろにtokenがないケースを示す\n * @param {AnalyzedToken} targetToken\n * @param allTokens\n * @returns {boolean}\n */\nconst isLastToken = (targetToken, allTokens) => {\n    const nextPunctureToken = findNextPunctureToken(targetToken, allTokens);\n    if (nextPunctureToken === undefined) {\n        return true;\n    }\n    const nextPunctureTokenSurface = nextPunctureToken.surface_form;\n    if (/[\\!\\?！？。]/.test(nextPunctureTokenSurface)) {\n        return true;\n    }\n};\n/**\n * targetTokenより後ろにあるtokenから切り口となるtokenを探す\n * @param targetToken\n * @param allTokens\n * @returns {AnalyzedToken|undefined}\n */\nconst findNextPunctureToken = (targetToken, allTokens) => {\n    const PUNCTUATION = /、|。/;\n    const CONJUGATED_TYPE = /特殊/;\n    const indexOfTargetToken = allTokens.indexOf(targetToken);\n    // value is collection of these tokens: [ {target}, token, token, nextTarget|PunctuationToken ]\n    const postTokens = allTokens.slice(indexOfTargetToken + 1);\n    return find(postTokens, token => {\n        // 接続、末尾なので切る\n        if (PUNCTUATION.test(token[\"surface_form\"])) {\n            return true;\n        }\n        // 次の特殊・がきたら\n        if (CONJUGATED_TYPE.test(token[\"conjugated_type\"])) {\n            return true;\n        }\n        // 明示的なtokenがない場合は、名詞がきたらそこで切ってしまう\n        if (token[\"pos\"] === \"名詞\") {\n            return true;\n        }\n        return false;\n    });\n};\n/**\n * tokensからAnalyzedTokenにmapを作る\n * @param {AnalyzedToken[]}tokens\n * @returns {function(token: AnalyzedToken)}\n */\nconst mapToAnalyzedResult = tokens => {\n    /**\n     * @param {AnalyzedToken} token\n     * @return {AnalyzedResultObject}\n     */\n    return function mapTokenToAnalyzedResult(token) {\n        const indexOfTargetToken = tokens.indexOf(token);\n        const nextPunctureToken = findNextPunctureToken(token, tokens);\n        // if has not next token, use between token <--> last.\n        const nextTokenIndex = nextPunctureToken ? tokens.indexOf(nextPunctureToken) : tokens.length;\n        const valueTokens = tokens.slice(indexOfTargetToken, nextTokenIndex + 1);\n        const value = valueTokens.map(token => token[\"surface_form\"]).join(\"\");\n        return {\n            type: token[\"conjugated_type\"],\n            value: value,\n            surface: token[\"surface_form\"],\n            // index start with 0\n            index: token[\"word_position\"] - 1,\n            /**\n             * @type {AnalyzedToken}\n             */\n            token: ObjectAssign({}, token)\n        };\n    };\n};\n/**\n * `text`から敬体(ですます調)と常体(である調)を取り出した結果を返します。\n * @param {string} text\n * @param {Object} options\n * @returns {Promise.<AnalyzedResultObject[]>}\n */\nexport function analyze(text, options = defaultOptions) {\n    const ignoreConjunction = options.ignoreConjunction !== undefined\n        ? options.ignoreConjunction\n        : defaultOptions.ignoreConjunction;\n    return getTokenizer().then(tokenizer => {\n        const tokens = _tokensCacheMap[text] ? _tokensCacheMap[text] : tokenizer.tokenizeForSentence(text);\n        _tokensCacheMap[text] = tokens;\n        const filterByType = tokens.filter((token, index) => {\n            const nextToken = tokens[index + 1];\n            // token[特殊・ダ] + nextToken[アル] なら 常体(である調) として認識する\n            const conjugatedType = token[\"conjugated_type\"];\n            if (conjugatedType === Types.dearu) {\n                // \"である\" を取り出す。この時点では接続なのか末尾なのかは区別できない\n                if (token[\"pos\"] === \"助動詞\" && token[\"conjugated_form\"] === \"連用形\") {\n                    if (nextToken && nextToken[\"conjugated_type\"] === \"五段・ラ行アル\") {\n                        // 文末の\"である\"のみを許容する場合は文末であるかどうかを調べる\n                        if (ignoreConjunction) {\n                            return isLastToken(token, tokens);\n                        } else {\n                            return true;\n                        }\n                    }\n                }\n            } else if (conjugatedType === Types.desu) {\n                // TODO: can omit?\n                if (token[\"conjugated_form\"] === \"基本形\") {\n                    // 文末の\"です\"のみを許容する場合は、文末であるかどうかを調べる\n                    if (ignoreConjunction) {\n                        return isLastToken(token, tokens);\n                    } else {\n                        return true;\n                    }\n                }\n            }\n        });\n        return filterByType.map(mapToAnalyzedResult(tokens));\n    });\n}\n/**\n * `text` の敬体(ですます調)について解析し、敬体(ですます調)のトークン情報を返します。\n * @param {string} text\n * @param {Object} options\n * @return {Promise.<AnalyzedResultObject[]>}\n */\nexport function analyzeDesumasu(text, options = defaultOptions) {\n    return analyze(text, options).then(results => results.filter(isDesumasu));\n}\n/**\n * `text` の常体(である調)について解析し、常体(である調)のトークン情報を返します。\n * @param {string} text\n * @param {Object} options\n * @return {Promise.<AnalyzedResultObject[]>}\n */\nexport function analyzeDearu(text, options = defaultOptions) {\n    return analyze(text, options).then(results => results.filter(isDearu))\n}"]}