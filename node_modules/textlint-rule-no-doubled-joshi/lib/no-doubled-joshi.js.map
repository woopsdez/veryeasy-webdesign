{"version":3,"sources":["../src/no-doubled-joshi.js"],"names":["context","options","helper","minInterval","min_interval","defaultOptions","isStrict","strict","allow","separatorChars","Syntax","report","RuleError","Paragraph","node","isChildNode","Link","Image","BlockQuote","Emphasis","source","text","toString","isSentenceNode","type","Sentence","sentences","filter","then","checkSentence","sentence","tokens","tokenizer","tokenizeForSentence","raw","concatTokens","countableTokens","token","joshiTokenSurfaceKeyMap","createSurfaceKeyMap","Object","keys","forEach","key","joshiName","indexOf","matchExceptionRule","length","reduce","prev","current","startPosition","otherPosition","differenceIndex","originalIndex","originalIndexFromPosition","line","loc","start","column","word_position","padding","index","keyMap","tokenKey","push","pos_detail_1","surface_form"],"mappings":"AAAA;AACA;;;;;;kBAiEe,UAASA,OAAT,EAAgC;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAC3C,QAAMC,SAAS,mCAAeF,OAAf,CAAf;AACA;AACA,QAAMG,cAAcF,QAAQG,YAAR,IAAwBC,eAAeD,YAA3D;AACA,QAAME,WAAWL,QAAQM,MAAR,IAAkBF,eAAeE,MAAlD;AACA,QAAMC,QAAQP,QAAQO,KAAR,IAAiBH,eAAeG,KAA9C;AACA,QAAMC,iBAAiBR,QAAQQ,cAAR,IAA0BJ,eAAeI,cAAhE;AAN2C,QAOpCC,MAPoC,GAOPV,OAPO,CAOpCU,MAPoC;AAAA,QAO5BC,MAP4B,GAOPX,OAPO,CAO5BW,MAP4B;AAAA,QAOpBC,SAPoB,GAOPZ,OAPO,CAOpBY,SAPoB;;AAQ3C,+BACKF,OAAOG,SADZ,YACuBC,IADvB,EAC4B;AACpB,YAAIZ,OAAOa,WAAP,CAAmBD,IAAnB,EAAyB,CAACJ,OAAOM,IAAR,EAAcN,OAAOO,KAArB,EAA4BP,OAAOQ,UAAnC,EAA+CR,OAAOS,QAAtD,CAAzB,CAAJ,EAA+F;AAC3F;AACH;AACD,YAAMC,SAAS,mCAAiBN,IAAjB,CAAf;AACA,YAAMO,OAAOD,OAAOE,QAAP,EAAb;AACA,YAAMC,iBAAiB,SAAjBA,cAAiB,OAAQ;AAC3B,mBAAOT,KAAKU,IAAL,KAAc,yBAAeC,QAApC;AACH,SAFD;AAGA,YAAMC,YAAY,6BAAeL,IAAf,EAAqB;AACnCZ,4BAAgBA;AADmB,SAArB,EAEfkB,MAFe,CAERJ,cAFQ,CAAlB;AAGA,eAAO,+BAAeK,IAAf,CAAoB,qBAAa;AACpC,gBAAMC,gBAAgB,SAAhBA,aAAgB,CAACC,QAAD,EAAc;AAChC,oBAAMC,SAASC,UAAUC,mBAAV,CAA8BH,SAASI,GAAvC,CAAf;AACA;AACA;AACA;AACA;AACA,oBAAMC,eAAe,oCAAmBJ,MAAnB,CAArB;AACA,oBAAMK,kBAAkBD,aAAaR,MAAb,CAAoB,iBAAS;AACjD,wBAAIrB,QAAJ,EAAc;AACV,+BAAO,2BAAU+B,KAAV,CAAP;AACH;AACD;AACA;AACA;AACA,2BAAO,2BAAUA,KAAV,KAAoB,2BAAUA,KAAV,CAA3B;AACH,iBARuB,CAAxB;AASA,oBAAMC,0BAA0BC,oBAAoBH,eAApB,CAAhC;AACA;;;;;;;;AASAI,uBAAOC,IAAP,CAAYH,uBAAZ,EAAqCI,OAArC,CAA6C,eAAO;AAChD,wBAAMX,SAASO,wBAAwBK,GAAxB,CAAf;AACA,wBAAMC,YAAY,yCAAwBD,GAAxB,CAAlB;AACA;AACA,wBAAInC,MAAMqC,OAAN,CAAcD,SAAd,KAA4B,CAAhC,EAAmC;AAC/B;AACH;AACD;AACA,wBAAI,CAACtC,QAAL,EAAe;AACX,4BAAIwC,mBAAmBf,MAAnB,CAAJ,EAAgC;AAC5B;AACH;AACJ;AACD,wBAAIA,OAAOgB,MAAP,IAAiB,CAArB,EAAwB;AACpB,+BADoB,CACb;AACV;AACD;AACA;AACAhB,2BAAOiB,MAAP,CAAc,UAACC,IAAD,EAAOC,OAAP,EAAmB;AAC7B,4BAAMC,gBAAgBf,gBAAgBS,OAAhB,CAAwBI,IAAxB,CAAtB;AACA,4BAAMG,gBAAgBhB,gBAAgBS,OAAhB,CAAwBK,OAAxB,CAAtB;AACA;AACA,4BAAMG,kBAAkBD,gBAAgBD,aAAxC;AACA,4BAAIE,mBAAmBlD,WAAvB,EAAoC;AAChC,gCAAMmD,gBAAgBlC,OAAOmC,yBAAP,CAAiC;AACnDC,sCAAM1B,SAAS2B,GAAT,CAAaC,KAAb,CAAmBF,IAD0B;AAEnDG,wCAAQ7B,SAAS2B,GAAT,CAAaC,KAAb,CAAmBC,MAAnB,IAA6BT,QAAQU,aAAR,GAAwB,CAArD;AAF2C,6BAAjC,CAAtB;AAIA;AACA,gCAAMC,UAAU;AACZC,uCAAOR;AADK,6BAAhB;AAGA3C,mCAAOG,IAAP,EAAa,IAAIF,SAAJ,yGAAmCgC,SAAnC,gEAA2DiB,OAA3D,CAAb;AACH;AACD,+BAAOX,OAAP;AACH,qBAjBD;AAkBH,iBApCD;AAqCH,aA/DD;AAgEAxB,sBAAUgB,OAAV,CAAkBb,aAAlB;AACH,SAlEM,CAAP;AAmEH,KAhFL;AAkFH,C;;AA1JD;;AACA;;AACA;;AACA;;;;AACA;;;;;;AAMA;;;;;;;;AAQA,SAASU,mBAAT,CAA6BR,MAA7B,EAAqC;AACjC;AACA,WAAOA,OAAOJ,MAAP,wBAAyBqB,MAAzB,CAAgC,UAACe,MAAD,EAAS1B,KAAT,EAAmB;AACtD;AACA,YAAM2B,WAAW,kCAAiB3B,KAAjB,CAAjB;AACA,YAAI,CAAC0B,OAAOC,QAAP,CAAL,EAAuB;AACnBD,mBAAOC,QAAP,IAAmB,EAAnB;AACH;AACDD,eAAOC,QAAP,EAAiBC,IAAjB,CAAsB5B,KAAtB;AACA,eAAO0B,MAAP;AACH,KARM,EAQJ,EARI,CAAP;AASH;AACD,SAASjB,kBAAT,CAA4Bf,MAA5B,EAAoC;AAChC,QAAIM,QAAQN,OAAO,CAAP,CAAZ;AACA;AACA,QAAIM,MAAM6B,YAAN,KAAuB,KAA3B,EAAkC;AAC9B,eAAO,IAAP;AACH;AACD;AACA,QAAI7B,MAAM6B,YAAN,KAAuB,KAAvB,IAAgC7B,MAAM8B,YAAN,KAAuB,GAA3D,EAAgE;AAC5D,eAAO,IAAP;AACH;AACD;AACA,QAAI9B,MAAM6B,YAAN,KAAuB,MAAvB,IAAiC7B,MAAM8B,YAAN,KAAuB,GAA5D,EAAiE;AAC7D,eAAO,IAAP;AACH;AACD,WAAO,KAAP;AACH;AACD;;;AAGA,IAAM9D,iBAAiB;AACnBD,kBAAc,CADK;AAEnBG,YAAQ,KAFW;AAGnBC,WAAO,EAHY;AAInBC,oBAAgB,CAAC,GAAD,EAAM,GAAN,EAAW,GAAX,EAAgB,GAAhB,EAAqB,GAArB;AAJG,CAAvB;;AAOA;;;;;;;;AAkGC","file":"no-doubled-joshi.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport {RuleHelper} from \"textlint-rule-helper\";\nimport {getTokenizer} from \"kuromojin\";\nimport {split as splitSentences, Syntax as SentenceSyntax} from \"sentence-splitter\";\nimport StringSource from \"textlint-util-to-string\";\nimport {\n    is助詞Token, is読点Token,\n    concatJoishiTokens,\n    createKeyFromKey,\n    restoreToSurfaceFromKey\n} from \"./token-utils\";\n/**\n * Create token map object\n * {\n *  \"は:助詞.係助詞\": [token, token]\n * }\n * @param tokens\n * @returns {*}\n */\nfunction createSurfaceKeyMap(tokens) {\n    // 助詞のみを対象とする\n    return tokens.filter(is助詞Token).reduce((keyMap, token) => {\n        // \"は:助詞.係助詞\" : [token]\n        const tokenKey = createKeyFromKey(token);\n        if (!keyMap[tokenKey]) {\n            keyMap[tokenKey] = [];\n        }\n        keyMap[tokenKey].push(token);\n        return keyMap;\n    }, {});\n}\nfunction matchExceptionRule(tokens) {\n    let token = tokens[0];\n    // \"の\" の重なりは例外\n    if (token.pos_detail_1 === \"連体化\") {\n        return true;\n    }\n    // \"を\" の重なりは例外\n    if (token.pos_detail_1 === \"格助詞\" && token.surface_form === \"を\") {\n        return true;\n    }\n    // 接続助詞 \"て\" の重なりは例外\n    if (token.pos_detail_1 === \"接続助詞\" && token.surface_form === \"て\") {\n        return true;\n    }\n    return false;\n}\n/*\n default options\n */\nconst defaultOptions = {\n    min_interval: 1,\n    strict: false,\n    allow: [],\n    separatorChars: [\"。\", \"?\", \"!\", \"？\", \"！\"]\n};\n\n/*\n 1. Paragraph Node -> text\n 2. text -> sentences\n 3. tokenize sentence\n 4. report error if found word that match the rule.\n\n TODO: need abstraction\n */\nexport default function(context, options = {}) {\n    const helper = new RuleHelper(context);\n    // 最低間隔値\n    const minInterval = options.min_interval || defaultOptions.min_interval;\n    const isStrict = options.strict || defaultOptions.strict;\n    const allow = options.allow || defaultOptions.allow;\n    const separatorChars = options.separatorChars || defaultOptions.separatorChars;\n    const {Syntax, report, RuleError} = context;\n    return {\n        [Syntax.Paragraph](node){\n            if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {\n                return;\n            }\n            const source = new StringSource(node);\n            const text = source.toString();\n            const isSentenceNode = node => {\n                return node.type === SentenceSyntax.Sentence;\n            };\n            const sentences = splitSentences(text, {\n                separatorChars: separatorChars\n            }).filter(isSentenceNode);\n            return getTokenizer().then(tokenizer => {\n                const checkSentence = (sentence) => {\n                    const tokens = tokenizer.tokenizeForSentence(sentence.raw);\n                    // 助詞 + 助詞は 一つの助詞として扱う\n                    // https://github.com/textlint-ja/textlint-rule-no-doubled-joshi/issues/15\n                    // 連語(助詞)の対応\n                    // http://www.weblio.jp/parts-of-speech/%E9%80%A3%E8%AA%9E(%E5%8A%A9%E8%A9%9E)_1\n                    const concatTokens = concatJoishiTokens(tokens);\n                    const countableTokens = concatTokens.filter(token => {\n                        if (isStrict) {\n                            return is助詞Token(token);\n                        }\n                        // デフォルトでは、\"、\"を間隔値の距離としてカウントする\n                        // \"、\" があると助詞同士の距離が開くようにすることで、並列的な\"、\"の使い方を許容する目的\n                        // https://github.com/azu/textlint-rule-no-doubled-joshi/issues/2\n                        return is助詞Token(token) || is読点Token(token);\n                    });\n                    const joshiTokenSurfaceKeyMap = createSurfaceKeyMap(countableTokens);\n                    /*\n                     # Data Structure\n\n                     joshiTokens = [tokenA, tokenB, tokenC, tokenD, tokenE, tokenF]\n                     joshiTokenSurfaceKeyMap = {\n                         \"は:助詞.係助詞\": [tokenA, tokenC, tokenE],\n                         \"で:助詞.係助詞\": [tokenB, tokenD, tokenF]\n                     }\n                     */\n                    Object.keys(joshiTokenSurfaceKeyMap).forEach(key => {\n                        const tokens = joshiTokenSurfaceKeyMap[key];\n                        const joshiName = restoreToSurfaceFromKey(key);\n                        // check allow\n                        if (allow.indexOf(joshiName) >= 0) {\n                            return;\n                        }\n                        // strict mode ではない時例外を除去する\n                        if (!isStrict) {\n                            if (matchExceptionRule(tokens)) {\n                                return;\n                            }\n                        }\n                        if (tokens.length <= 1) {\n                            return;// no duplicated token\n                        }\n                        // if found differenceIndex less than\n                        // tokes are sorted ascending order\n                        tokens.reduce((prev, current) => {\n                            const startPosition = countableTokens.indexOf(prev);\n                            const otherPosition = countableTokens.indexOf(current);\n                            // 助詞token同士の距離が設定値以下ならエラーを報告する\n                            const differenceIndex = otherPosition - startPosition;\n                            if (differenceIndex <= minInterval) {\n                                const originalIndex = source.originalIndexFromPosition({\n                                    line: sentence.loc.start.line,\n                                    column: sentence.loc.start.column + (current.word_position - 1)\n                                });\n                                // padding positionを計算する\n                                const padding = {\n                                    index: originalIndex\n                                };\n                                report(node, new RuleError(`一文に二回以上利用されている助詞 \"${joshiName}\" がみつかりました。`, padding));\n                            }\n                            return current;\n                        });\n                    });\n                };\n                sentences.forEach(checkSentence);\n            });\n        }\n    }\n};\n"]}